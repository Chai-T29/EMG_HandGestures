# EMG Hand Gesture Classification

## Introduction

This project focuses on classifying hand gestures using Electromyography (EMG) data. The data is sourced from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/481/emg+data+for+gestures) and consists of recordings from 36 participants performing 8 distinct gestures. Each gesture lasts for 3 seconds, and the aim is to compare the performance of windowing versus non-windowing data processing techniques for gesture classification. This work evaluates deep learning and machine learning models, leveraging hardware acceleration for efficient signal processing, which has significant implications for real-time applications like robotic prosthetics.

## Contents
1. Introduction
  - Overview of the project and objectives.
2. Data Description
  - Source, structure, and characteristics of the dataset.
3. Data Preprocessing
  - Handling class imbalance, feature scaling, and data transformations.
4. Modeling Approaches
  - Windowing and non-windowing pipelines.
5. Evaluation Metrics
  - Accuracy, precision, recall, and AUC-ROC for performance comparison.
6. Visualization
  - Proportions of classes, confusion matrices, and other relevant plots.
7. Conclusion
  - Insights and future directions.
